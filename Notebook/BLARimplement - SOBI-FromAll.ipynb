{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BLARimplement - SOBI-FromAll.ipynb","provenance":[],"collapsed_sections":["UZfgcsaOUugf","WIF8weFhoPBc","VesFfYCw9XdI","efkAVta48wnd"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# BLAR - SOBI-FromAll model\n","\n","- Notebook thực hiện các bước để finetune model nhận diện chữ viết tắt/định nghĩa\n","\n","- Notebook này tham khảo phần code để huấn luyện mô hình BERT của notebook: https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT_only_first_wordpiece.ipynb\n","\n","\n"],"metadata":{"id":"GHcW7SP-8KgO"}},{"cell_type":"markdown","source":["# Chuẩn bị các thư viện cần thiết"],"metadata":{"id":"UZfgcsaOUugf"}},{"cell_type":"markdown","source":["Cài đặt thư viện bioc và transformers"],"metadata":{"id":"mQE8ZQWs85S8"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNgnmHf-MDG8","executionInfo":{"status":"ok","timestamp":1650960269265,"user_tz":-420,"elapsed":10942,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"58e7214d-4c0d-4b10-a7d7-1071e3c949da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bioc\n","  Downloading bioc-2.0.post4-py3-none-any.whl (37 kB)\n","Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: intervaltree in /usr/local/lib/python3.7/dist-packages (from bioc) (2.1.0)\n","Collecting jsonlines>=1.2.0\n","  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from bioc) (4.64.0)\n","Collecting lxml>=4.6.3\n","  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n","\u001b[K     |████████████████████████████████| 6.4 MB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines>=1.2.0->bioc) (21.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines>=1.2.0->bioc) (4.2.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 69.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 54.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 72.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from intervaltree->bioc) (2.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, lxml, jsonlines, huggingface-hub, transformers, bioc\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: lxml\n","    Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","Successfully installed bioc-2.0.post4 huggingface-hub-0.5.1 jsonlines-3.0.0 lxml-4.8.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"]}],"source":["pip install bioc transformers"]},{"cell_type":"code","source":["# import các thư viện\n","import os\n","import transformers\n","import bioc\n","import math\n","import torch\n","import pandas as pd\n","import numpy as np\n","from copy import deepcopy\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertForTokenClassification, AutoModelForTokenClassification\n","from sklearn.metrics import accuracy_score\n","from matplotlib import pyplot as plt"],"metadata":{"id":"ZCKoC-xHoPBb","executionInfo":{"status":"ok","timestamp":1650960274799,"user_tz":-420,"elapsed":5549,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Kiểm tra colab sử dụng GPU để tăng tốc độ train\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960274801,"user_tz":-420,"elapsed":30,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"5500ff9a-6745-4da1-c905-da35716f1ef6","id":"fVtQ0PlaoPBb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["# Import data"],"metadata":{"id":"WIF8weFhoPBc"}},{"cell_type":"code","source":["#@title Thực hiện import data bằng 1 trong 2 cách\n","#@markdown Cách 1: tải folder BLAR về google drive\n","\n","#@markdown Cách 2: huấn luyện thử mô hình, tải dữ liệu về ổ cứng tạm thời của colab\n","\n","method = \"download_to_temporary_disk\" #@param [\"download_to_google_drive\", \"download_to_temporary_disk\"]\n","\n","\n","if method == 'download_to_google_drive':\n","  \n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  os.chdir('/content/drive/MyDrive/Colab Notebooks/BLAR data') ##Đổi về directory trong drive\n","\n","else:\n","  os.chdir('/content')\n","  directory = './corpus'\n","  if not os.path.exists(directory):\n","      os.makedirs(directory)\n","  os.chdir(directory)\n","  ## Download data về disk\n","  !gdown --id 16hOCtaVyuE2LK_n7mHNO_ptm_A-A8kjV\n","  !gdown --id 1Mj80pavNCcIHB7_e59DVQyv0EoS8bI6a\n","  os.chdir('/content')\n","\n","  directory = './model/model_SOBI'\n","  if not os.path.exists(directory):\n","      os.makedirs(directory)\n","  os.chdir(directory)\n","  ## Download data về disk\n","  !gdown --id 1Xg7XBdIWs5k76KEB9J1pG8HikPsIdnKM\n","  !gdown --id 1rjDB8_GmTAvBrzu8qp7TfxORl0zIMm1b\n","  !gdown --id 1MvJ0Auu0l_XrjcM9prj0xj-E9ckMXO98\n","  os.chdir('/content')\n","\n","  directory = './model/2stepFromAllSentenceModel'\n","  if not os.path.exists(directory):\n","      os.makedirs(directory)\n","  os.chdir(directory)\n","  ## Download data về disk\n","  !gdown --id 1Lut7rci259_d3waHkdRjS3MGLwBN02Pe\n","  !gdown --id 1AIBtnfEYgJlmXFBzT0kZrEVnnBfyTjTL\n","  !gdown --id 10-U7cjGOiZ6Nty7OC3BCtyswP6ilk4VY\n","  os.chdir('/content')\n","\n","## Load data từ google drive\n","### BIOADI corpus\n","from bioc import biocxml\n","with open('./corpus/bioadi_bioc_gold.xml', 'r') as fp:\n","  gold_raw = biocxml.load(fp)\n","\n","### AB3P corpus\n","from bioc import biocxml\n","with open('./corpus/Ab3P_bioc_gold.xml', 'r') as fp:\n","  ab3p = biocxml.load(fp)\n"],"metadata":{"cellView":"form","id":"XYZEx23CVudP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960510650,"user_tz":-420,"elapsed":24574,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"beeb6434-f3ec-4b13-efc9-782493075671"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=16hOCtaVyuE2LK_n7mHNO_ptm_A-A8kjV\n","To: /content/corpus/bioadi_bioc_gold.xml\n","100% 2.58M/2.58M [00:00<00:00, 232MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1Mj80pavNCcIHB7_e59DVQyv0EoS8bI6a\n","To: /content/corpus/Ab3P_bioc_gold.xml\n","100% 2.36M/2.36M [00:00<00:00, 246MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1Xg7XBdIWs5k76KEB9J1pG8HikPsIdnKM\n","To: /content/model/model_SOBI/config.json\n","100% 883/883 [00:00<00:00, 1.42MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1rjDB8_GmTAvBrzu8qp7TfxORl0zIMm1b\n","To: /content/model/model_SOBI/pytorch_model.bin\n","100% 437M/437M [00:01<00:00, 246MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1MvJ0Auu0l_XrjcM9prj0xj-E9ckMXO98\n","To: /content/model/model_SOBI/vocab.txt\n","100% 222k/222k [00:00<00:00, 105MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1Lut7rci259_d3waHkdRjS3MGLwBN02Pe\n","To: /content/model/2stepFromAllSentenceModel/config.json\n","100% 959/959 [00:00<00:00, 1.91MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=1AIBtnfEYgJlmXFBzT0kZrEVnnBfyTjTL\n","To: /content/model/2stepFromAllSentenceModel/pytorch_model.bin\n","100% 437M/437M [00:01<00:00, 295MB/s]\n","/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  category=FutureWarning,\n","Downloading...\n","From: https://drive.google.com/uc?id=10-U7cjGOiZ6Nty7OC3BCtyswP6ilk4VY\n","To: /content/model/2stepFromAllSentenceModel/vocab.txt\n","100% 222k/222k [00:00<00:00, 70.8MB/s]\n"]}]},{"cell_type":"code","source":["# Tạo corpus phụ gồm các văn bản không chứa từ viết tắt\n","n = len(gold_raw.documents)\n","noAcronym = []\n","gold_noAcronym = bioc.bioc.BioCCollection()\n","for i, document in enumerate(gold_raw.documents):\n","  if len(document.passages[0].annotations) == 0:\n","    gold_noAcronym.add_document(document)\n","    noAcronym.append(i)"],"metadata":{"id":"9O77CO-QCsx6","executionInfo":{"status":"ok","timestamp":1650960510650,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Tạo corpus phụ gồm các văn bản chứa từ viết tắt\n","n = len(gold_raw.documents)\n","Acronym = []\n","gold = bioc.bioc.BioCCollection()\n","for i, document in enumerate(gold_raw.documents):\n","  if len(document.passages[0].annotations) != 0:\n","    gold.add_document(document)\n","    Acronym.append(i)"],"metadata":{"id":"NSwvknWig941","executionInfo":{"status":"ok","timestamp":1650960510651,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["#Load model"],"metadata":{"id":"VesFfYCw9XdI"}},{"cell_type":"code","source":["# Load model for token classification\n","directory = \"./model/2stepFromAllSentenceModel\" # sử dụng model FromAllSentence\n","tokenizer = transformers.AutoTokenizer.from_pretrained(directory, local_files_only=True)\n","model = transformers.AutoModelForTokenClassification.from_pretrained(directory, local_files_only=True)\n","model.to(device)\n","\n","# decoding dict for token model\n","labels_to_ids = {'B-LF':0,\n","                 'I-LF':1,\n","                 'L-LF':2,\n","                 'O':3,\n","                 'U-SF':4,\n","                 'U-PR':5,\n","                 'TAG':6}\n","ids_to_labels = {v:k for k,v in labels_to_ids.items()}"],"metadata":{"id":"I9Qesj1g0z_9","executionInfo":{"status":"ok","timestamp":1650960526163,"user_tz":-420,"elapsed":15517,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Load model for sentence classification\n","directory = \"./model/model_SOBI\" # sử dụng model SOBI\n","tokenizer = transformers.AutoTokenizer.from_pretrained(directory, local_files_only=True)\n","model_seq = transformers.AutoModelForTokenClassification.from_pretrained(directory, local_files_only=True)\n","model_seq.to(device)\n","\n","# decoding dict for sentence model\n","labels_to_ids_sentence = {'B':0,'I':1,'S':2, 'O':3,'SpecialToken':-100}\n","ids_to_labels_sentence = {0:'B',1:'I',2:'S', 3: 'O', -100:'SpecialToken'}"],"metadata":{"id":"4mE-lxSOAgeC","executionInfo":{"status":"ok","timestamp":1650960527426,"user_tz":-420,"elapsed":1288,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# Model inference"],"metadata":{"id":"HNro-YsA-mte"}},{"cell_type":"markdown","source":["##Functions"],"metadata":{"id":"efkAVta48wnd"}},{"cell_type":"code","source":["#@title Create dataframe of true LF-SF (for corpus data)\n","def trueLFSF(corpus,idx):\n","  if corpus == 'ab3p':\n","    passage = ab3p.documents[idx].passages[1]\n","  elif corpus == 'bioadi':\n","    passage = gold_raw.documents[idx].passages[0]\n","  else:\n","    print('no true LF-SF')\n","\n","  text = passage.text\n","  annotations = passage.annotations\n","  LF = []\n","  SF = []\n","\n","  for i, annotation in enumerate(annotations):\n","    if i%2 == 0:\n","      SF.append(annotation.text.lower())\n","    else:\n","      LF.append(annotation.text.lower())\n","  df = pd.DataFrame({'truelongform':LF,'trueshortform':SF})\n","  return df\n"],"metadata":{"id":"wzBpRYH4Dykw","cellView":"form","executionInfo":{"status":"ok","timestamp":1650960527427,"user_tz":-420,"elapsed":14,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Create dataframe of predicted LF-SF "],"metadata":{"id":"mZ34y5ZWAseo"}},{"cell_type":"code","source":["#@title Functions for step 2\n","#@markdown Load các hàm cho token classification model step 2\n","MAX_LEN = 512\n","alphabet = 'abcdefghijklmnopqrstuvwxyz0123456789'\n","\n","def ExtractStringFromToken(listOfToken):\n","  # this function will decode list of token to string of text\n","  string = ''\n","  for token in listOfToken:\n","    if token[0] == '[' and token[-1] == ']':\n","      continue\n","    elif token[0:2] == '##':\n","      string = string + token[2:]\n","    elif token[0] not in alphabet:\n","      string = string + token\n","    elif token[0] in alphabet and string == '':\n","      string = string + token\n","    elif token[0] in alphabet and (string[-1] not in alphabet and string[-1] not in '+)'):\n","      string = string + token\n","    else:\n","      string = string + ' ' + token\n","  return string\n","\n","def ExtractLFSF(wp_preds):\n","  # this function will infer LF-SF pairs from list of tagged tokens\n","  LF = []\n","  SF = []\n","  for i in range(len(wp_preds)-1):\n","    if wp_preds[i][1] == 'B-LF':\n","      for j in range(i+1,min(i+31,len(wp_preds)-1)):\n","        if wp_preds[j][1] == 'L-LF':\n","          for k in range(j+1,min(j+5,len(wp_preds))):\n","            if wp_preds[k][1] == 'U-SF':\n","              for l in range(k, min(k+12,len(wp_preds))):\n","                if wp_preds[l][1] != 'U-SF':\n","                  if wp_preds[l][0][0:2] != '##':\n","                    lflist = [idx[0] for idx in wp_preds[i:k-1]]\n","                    longform = ExtractStringFromToken(lflist)\n","                    if longform != '':\n","                      LF.append(longform)\n","                    sflist = [idx[0] for idx in wp_preds[k:l]]\n","                    shortform = ExtractStringFromToken(sflist)\n","                    if shortform != '':\n","                      SF.append(shortform)\n","                  break\n","              break  \n","          break\n","        else:\n","          if wp_preds[j+1][1] == 'U-SF':\n","            for k in range(j+1, min(j+12,len(wp_preds))):\n","              if wp_preds[k][1] != 'U-SF':\n","                if wp_preds[k][0][0:2] != '##':\n","                  lflist = [idx[0] for idx in wp_preds[i:j]]\n","                  longform = ExtractStringFromToken(lflist)\n","                  if longform != '':\n","                    LF.append(longform)\n","                  sflist = [idx[0] for idx in wp_preds[j+1:k]]\n","                  shortform = ExtractStringFromToken(sflist)\n","                  if shortform != '':\n","                    SF.append(shortform)\n","                break\n","            break\n","\n","    elif wp_preds[i][1] == 'O' and wp_preds[i][0][0:2] != '##' and wp_preds[i+1][1] == 'I-LF':\n","      for j in range(i+1,min(i+21,len(wp_preds)-1)):\n","        if wp_preds[j][1] == 'L-LF':\n","          for k in range(j+1,min(j+5,len(wp_preds))):\n","            if wp_preds[k][1] == 'U-SF':\n","              for l in range(k, min(k+10,len(wp_preds))):\n","                if wp_preds[l][1] != 'U-SF':\n","                  if wp_preds[l][0][0:2] != '##':\n","                    lflist = [idx[0] for idx in wp_preds[i:k-1]]\n","                    longform = ExtractStringFromToken(lflist)\n","                    if longform != '':\n","                      LF.append(longform)\n","                    sflist = [idx[0] for idx in wp_preds[k:l]]\n","                    shortform = ExtractStringFromToken(sflist)\n","                    if shortform != '':\n","                      SF.append(shortform)\n","                  break\n","              break  \n","          break\n","\n","    elif wp_preds[i][1] == 'O' and wp_preds[i][0][0:2] == '##' and wp_preds[i+1][1] == 'I-LF':\n","      for j in range(i+1,min(i+21,len(wp_preds)-1)):\n","        if wp_preds[j][1] == 'L-LF':\n","          for k in range(j+1,min(j+5,len(wp_preds))):\n","            if wp_preds[k][1] == 'U-SF':\n","              for l in range(k, min(k+10,len(wp_preds))):\n","                if wp_preds[l][1] != 'U-SF':\n","                  if wp_preds[l][0][0:2] != '##':\n","                    lflist = [idx[0] for idx in wp_preds[i+1:k-1]]\n","                    longform = ExtractStringFromToken(lflist)\n","                    if longform != '':\n","                      LF.append(longform)\n","                    sflist = [idx[0] for idx in wp_preds[k:l]]\n","                    shortform = ExtractStringFromToken(sflist)\n","                    if shortform != '':\n","                      SF.append(shortform)\n","                  break\n","              break  \n","          break\n","\n","  return pd.DataFrame({'longform':LF, 'shortform':SF})  \n","\n","\n","def PredictToken(sentence):\n","  #This function perform token classification with input as text\n","  inputs = tokenizer(sentence, \n","                   return_offsets_mapping=True, \n","                   padding='max_length', \n","                   truncation=True, \n","                   max_length=MAX_LEN,\n","                   return_tensors=\"pt\")\n","\n","  # move to gpu\n","  ids = inputs[\"input_ids\"].to(device)\n","  mask = inputs[\"attention_mask\"].to(device)\n","  # forward pass\n","  outputs = model(ids, attention_mask=mask)\n","  logits = outputs[0]\n","\n","  active_logits = logits.view(-1, 7) # shape (batch_size * seq_len, num_labels)\n","  flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n","\n","  tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n","  token_predictions = [ids_to_labels[i] for i in flattened_predictions.cpu().numpy()]\n","  wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n","  return wp_preds\n","\n","\n","def predictLFSFFromSentence(sentence):\n","  # This function returns predicted LF-SF pairs from text\n","  wp_preds = PredictToken(sentence)\n","  return ExtractLFSF(wp_preds)"],"metadata":{"id":"LgTkrxWiaB16","cellView":"form","executionInfo":{"status":"ok","timestamp":1650960527428,"user_tz":-420,"elapsed":13,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["#@title Functions for 2 step model\n","#@markdown Load các hàm cho mô hình hai bước hoàn chỉnh\n","\n","\n","def ExtractSentenceWithAcronym(original_passage):\n","  # this function will return new passage with annotated sentences\n","\n","\n","  passage = deepcopy(original_passage)\n","  text = passage.text\n","  # extract annotation\n","  sf_offset_stack_unsort = dict()\n","  for i, annotation in enumerate(passage.annotations):\n","    if i%2 == 0:\n","      sf_offset_stack_unsort[passage.annotations[i].total_span.offset] = i #extract the SF offset only\n","  offsetList = [offset for offset,i in sf_offset_stack_unsort.items()]\n","  \n","  sf_offset_stack = []\n","  while offsetList:\n","    minoffset = min(offsetList)\n","    idx = sf_offset_stack_unsort[minoffset]\n","    sf_offset_stack.append([idx, passage.annotations[idx].total_span.offset])\n","    offsetList.remove(minoffset)\n","\n","  \n","  # Sentence extraction\n","  ## Presumption: \n","  ### SF always stands before LF in corpus annotation list\n","  ### Sentence extraction by: '. '\n","  ### Sentence starts with CASED character\n","  ### Sentence length > 20 characters\n","\n","  rawSentenceList = text.split('. ') #split passage to list of sentence\n","  cased_alphabet = 'ABCEDEFGHIJKLMNOPQRSTUVWXYZ'\n","  sentenceList = []\n","  for i, raw_sentence in enumerate(rawSentenceList):\n","    if raw_sentence[-1] != '.':\n","      raw_sentence += '.' # add . if sentence doesn't have\n","    if raw_sentence[0] in cased_alphabet and len(raw_sentence) >10:\n","      sentenceList.append(raw_sentence)\n","    else:\n","      if sentenceList:\n","        sentenceList[-1] += ' ' + raw_sentence\n","      else:\n","        sentenceList.append(raw_sentence)\n","\n","\n","  # Add annotation for sentence\n","  pointer = 0\n","  for sentence in sentenceList:\n","    bioc_sentence = bioc.bioc.BioCSentence()\n","    bioc_sentence.text = sentence\n","    while len(sf_offset_stack):\n","      if sf_offset_stack[0][1] < pointer + len(sentence):\n","        sf = sf_offset_stack.pop(0)\n","        bioc_sentence.annotations.append(passage.annotations[sf[0]]) # get SF annotation\n","        bioc_sentence.annotations.append(passage.annotations[sf[0]+1]) # get LF annotation\n","        bioc_sentence.annotations[-2].locations[0].offset -= pointer # change SF offset to sentence (originally was offset passage)\n","        bioc_sentence.annotations[-1].locations[0].offset -= pointer # change LF offset to sentence (originally was offset passage)  \n","      else:\n","        break\n","    bioc_sentence.offset = pointer\n","    pointer += len(sentence) + 1 # move pointer to next sentence, 1 for .\n","    passage.add_sentence(bioc_sentence) # add sentence to passage\n","      \n","  return passage\n","        \n","\n","def PredictTokenSentence(text):\n","  # This function returns predictions of token in Sentence Classification task\n","  text = text.split(' ')\n","  inputs = tokenizer(text,\n","                    is_split_into_words=True,\n","                    return_offsets_mapping=True, \n","                    padding='max_length', \n","                    truncation=True, \n","                    max_length=512,\n","                    return_tensors=\"pt\")\n","  # move to gpu\n","  ids = inputs[\"input_ids\"].to(device)\n","  mask = inputs[\"attention_mask\"].to(device)\n","  # forward pass\n","  outputs = model_seq(ids, attention_mask=mask)\n","  logits = outputs[0]\n","\n","  active_logits = logits.view(-1, model_seq.num_labels) # shape (batch_size * seq_len, num_labels)\n","  flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n","\n","  tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n","  token_predictions = [ids_to_labels_sentence[i] for i in flattened_predictions.cpu().numpy()]\n","  wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n","\n","  prediction = []\n","  for token_pred, mapping in zip(wp_preds, inputs[\"offset_mapping\"].squeeze().tolist()):\n","    #only predictions on first word pieces are important\n","    if mapping[0] == 0 and mapping[1] != 0:\n","      prediction.append(token_pred[1])\n","    else:\n","      continue\n","  return prediction\n","\n","def PredictSentenceWithABBR(text):\n","  # This function returns list of predicted correct sentence with LF/SF pairs\n","  text_split = text.split(' ')\n","  prediction = PredictTokenSentence(text)\n","  sentenceList = []\n","  for i in range(len(prediction)-1):\n","    if prediction[i] == 'B':\n","      for j in range(i+1, len(prediction)):\n","        if prediction[j] in 'BS':\n","          sentence = ' '.join(text_split[i:j])\n","          if j-i>4: # at least 5 words per sentence\n","            sentenceList.append(sentence)\n","          break\n","        elif j == len(prediction)-1:\n","          sentence = ' '.join(text_split[i:])\n","          sentenceList.append(sentence)\n","          break               \n","  return sentenceList\n","  \n","def predictLFSFFromPassage(passage):\n","  # This function returns predicted LF-SF pairs with input as text of passage\n","  l = [pd.DataFrame(columns = ['longform','shortform'])]\n","  for sentence in PredictSentenceWithABBR(passage):\n","    l.append(predictLFSFFromSentence(sentence))\n","  if l:\n","    return pd.concat(l, ignore_index = True)"],"metadata":{"id":"AvyH-S4dj_Pi","cellView":"form","executionInfo":{"status":"ok","timestamp":1650960527429,"user_tz":-420,"elapsed":13,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### So sánh cặp từ viết tắt/định nghĩa dự đoán và từ giá trị thực"],"metadata":{"id":"yCt2JB9rJLfT"}},{"cell_type":"code","source":["#@title Functions\n","def BuildContigencyTable(sentence,corpus,idx):\n","  prediction = predictLFSFFromPassage(sentence)\n","  truelabels = trueLFSF(corpus,idx)\n","  predictionList = [tuple(prediction.loc[i,]) for i in range(len(prediction))]\n","  truelabelsList = [tuple(truelabels.loc[i,]) for i in range(len(truelabels))]\n","  ls = []\n","  for item in predictionList:\n","    if item in truelabelsList:\n","      ls.append(pd.DataFrame({'longform':item[0],\n","                              'shortform':item[1],\n","                              'truelongform':item[0],\n","                              'trueshortform':item[1],\n","                              'TP':[1],'FP':[0],'FN':[0],'M':[0],'idx':[idx]}))\n","      truelabelsList.remove(item)\n","    else:\n","      if item[1] in list(truelabels['trueshortform']):\n","        ls.append(pd.DataFrame({'longform':item[0],\n","                                'shortform':item[1],\n","                                'truelongform':'NaN',\n","                                'trueshortform':'NaN',\n","                                'TP':[0],'FP':[0], 'FN':[0], 'M':[0],'idx':[idx]}))\n","      else:\n","        ls.append(pd.DataFrame({'longform':item[0],\n","                                'shortform':item[1],\n","                                'truelongform':'NaN',\n","                                'trueshortform':'NaN',\n","                                'TP':[0],'FP':[1], 'FN':[0],'M':[0],'idx':[idx]}))\n","\n","  for item in truelabelsList:\n","    if item[1] in list(prediction['shortform']):\n","      ls.append(pd.DataFrame({'longform':'NaN',\n","                              'shortform':'NaN',\n","                              'truelongform':item[0],\n","                              'trueshortform':item[1],\n","                              'TP':[0],'FP':[0],'FN':[0],'M':[1],'idx':[idx]}))\n","    else:\n","      ls.append(pd.DataFrame({'longform':'NaN',\n","                              'shortform':'NaN',\n","                              'truelongform':item[0],\n","                              'trueshortform':item[1],\n","                              'TP':[0],'FP':[0],'FN':[1],'M':[0],'idx':[idx]}))\n","  if len(ls):\n","    contigencyTable = pd.concat(ls, ignore_index = True)\n","    return contigencyTable\n","  else:\n","    return pd.DataFrame()"],"metadata":{"id":"TS5x-5o_xnDE","cellView":"form","executionInfo":{"status":"ok","timestamp":1650960528124,"user_tz":-420,"elapsed":63,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#@title So sánh\n","corpus = \"bioadi\" #@param [\"ab3p\", \"bioadi\"]\n","index = 200 #@param {type:\"integer\"}\n","\n","if corpus == 'ab3p':\n","  passage = ab3p.documents[index].passages[1].text\n","else:\n","  passage = gold_raw.documents[index].passages[0].text\n","\n","print(f\"Văn bản cần dự đoán: {passage}\")\n","BuildContigencyTable(passage,corpus,index)\n"],"metadata":{"id":"eIk-AeUyiDIu","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1650960528126,"user_tz":-420,"elapsed":62,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"c4c5e18a-c492-485d-f5d9-6a0090541526"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Văn bản cần dự đoán: Molecular cloning, expression, and chromosomal localization of a human brain-specific Na(+)-dependent inorganic phosphate cotransporter. We describe the molecular cloning of a cDNA encoding a human brain Na(+)-dependent inorganic phosphate (P(i)) cotransporter (hBNPI). The nucleotide and deduced amino acid sequences of hBNPI reveal a protein of 560 amino acids with six to eight putative transmembrane segments. hBNPI shares a high degree of homology with other Na(+)-dependent inorganic P(i) cotransporters, including those found in rat brain and human and rabbit kidney. Expression of hBNPI in COS-1 cells results in Na(+)-dependent P(i) uptake. Northern blot analysis demonstrates that hBNPI mRNA is expressed predominantly in brain and most abundantly in neuron-enriched regions such as the amygdala and hippocampus. Moderate levels of expression are also observed in glia-enriched areas such as the corpus callosum, and low levels are observed in the substantia nigra, subthalamic nuclei, and thalamus. In situ hybridization histochemistry reveals relatively high levels of hBNPI mRNA in pyramidal neurons of the cerebral cortex and hippocampus and in granule neurons of dentate gyrus. The level of hBNPI mRNA is quite low in fetal compared with adult human brain, suggesting developmental regulation of hBNPI gene expression. Southern analyses of nine eukaryotic genomic DNAs probed under stringent conditions with hBNPI cDNA revealed that the hBNPI gene is highly conserved during vertebrate evolution and that each gene is most likely present as a single copy. Using fluorescent in situ hybridization, we localized hBNPI to the long arm of chromosome 19 (19q13) in close proximity to the late-onset familial Alzheimer's disease locus.\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            longform shortform  \\\n","0  brain na(+)-dependent inorganic phosphate(p(i)...     hbnpi   \n","1  na(+)-dependent inorganic phosphate(p(i)) cotr...     hbnpi   \n","2                                                NaN       NaN   \n","3                                                NaN       NaN   \n","\n","                                        truelongform trueshortform  TP  FP  \\\n","0                                                NaN           NaN   0   0   \n","1                                                NaN           NaN   0   0   \n","2                                inorganic phosphate          p(i)   0   0   \n","3  human brain na(+)-dependent inorganic phosphat...         hbnpi   0   0   \n","\n","   FN  M  idx  \n","0   0  0  200  \n","1   0  0  200  \n","2   1  0  200  \n","3   0  1  200  "],"text/html":["\n","  <div id=\"df-0c1a012b-13ab-465c-aa2a-1e008020e752\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longform</th>\n","      <th>shortform</th>\n","      <th>truelongform</th>\n","      <th>trueshortform</th>\n","      <th>TP</th>\n","      <th>FP</th>\n","      <th>FN</th>\n","      <th>M</th>\n","      <th>idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>brain na(+)-dependent inorganic phosphate(p(i)...</td>\n","      <td>hbnpi</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>na(+)-dependent inorganic phosphate(p(i)) cotr...</td>\n","      <td>hbnpi</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>inorganic phosphate</td>\n","      <td>p(i)</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>200</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>human brain na(+)-dependent inorganic phosphat...</td>\n","      <td>hbnpi</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c1a012b-13ab-465c-aa2a-1e008020e752')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0c1a012b-13ab-465c-aa2a-1e008020e752 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0c1a012b-13ab-465c-aa2a-1e008020e752');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# Kiểm tra độ chính xác trên ngữ liệu AB3P"],"metadata":{"id":"fwP4daOFgmcK"}},{"cell_type":"code","source":["#@title Functions\n","# Create contigency table for whole ab3p data\n","table = pd.DataFrame()\n","contigency_list = []\n","for idx in range(len(ab3p.documents)):\n","  if idx%50 == 0:\n","    print(idx, 'item done')\n","  sentence = ab3p.documents[idx].passages[1].text\n","  corpus = 'ab3p'\n","  contigency_list.append(BuildContigencyTable(sentence,corpus,idx))\n","final_contigency_table = pd.concat(contigency_list, ignore_index = True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrKimaxPe2pT","executionInfo":{"status":"ok","timestamp":1650960585273,"user_tz":-420,"elapsed":57198,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"828b7bf6-ab16-4491-d2c6-aa3f9c16d357","cellView":"form"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["0 item done\n","50 item done\n","100 item done\n","150 item done\n","200 item done\n","250 item done\n","300 item done\n","350 item done\n","400 item done\n","450 item done\n","500 item done\n","550 item done\n","600 item done\n","650 item done\n","700 item done\n","750 item done\n","800 item done\n","850 item done\n","900 item done\n","950 item done\n","1000 item done\n","1050 item done\n","1100 item done\n","1150 item done\n","1200 item done\n"]}]},{"cell_type":"code","source":["#@title Xem bảng so sánh dự đoán và kết quả thật\n","# show contigency table\n","final_contigency_table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"7tjJdld0-uW8","executionInfo":{"status":"ok","timestamp":1650960585282,"user_tz":-420,"elapsed":87,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"9ce10960-4f7b-415d-e186-8619413bb21c","cellView":"form"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                longform shortform  \\\n","0                     general anesthesia        ga   \n","1                     multiple sclerosis        ms   \n","2                    5-hydroxytryptamine       5ht   \n","3                   impedance cardiogram       icg   \n","4                first derivative of icg     dz/dt   \n","...                                  ...       ...   \n","1497                      sialyl lewis x    sle(x)   \n","1498  transcriptional regulatory network       trn   \n","1499                        methoxychlor       mxc   \n","1500      gonadotropin-releasing hormone      gnrh   \n","1501                      fanconi anemia        fa   \n","\n","                            truelongform trueshortform  TP  FP  FN  M   idx  \n","0                     general anesthesia            ga   1   0   0  0     2  \n","1                     multiple sclerosis            ms   1   0   0  0     5  \n","2                    5-hydroxytryptamine           5ht   1   0   0  0     6  \n","3                   impedance cardiogram           icg   1   0   0  0    10  \n","4                                    NaN           NaN   0   1   0  0    10  \n","...                                  ...           ...  ..  ..  .. ..   ...  \n","1497                      sialyl lewis x        sle(x)   1   0   0  0  1242  \n","1498  transcriptional regulatory network           trn   1   0   0  0  1245  \n","1499                        methoxychlor           mxc   1   0   0  0  1246  \n","1500      gonadotropin-releasing hormone          gnrh   1   0   0  0  1246  \n","1501                      fanconi anemia            fa   1   0   0  0  1249  \n","\n","[1502 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-5eb80a58-125b-44fe-8251-f0cb753b2bf2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longform</th>\n","      <th>shortform</th>\n","      <th>truelongform</th>\n","      <th>trueshortform</th>\n","      <th>TP</th>\n","      <th>FP</th>\n","      <th>FN</th>\n","      <th>M</th>\n","      <th>idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>general anesthesia</td>\n","      <td>ga</td>\n","      <td>general anesthesia</td>\n","      <td>ga</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>multiple sclerosis</td>\n","      <td>ms</td>\n","      <td>multiple sclerosis</td>\n","      <td>ms</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5-hydroxytryptamine</td>\n","      <td>5ht</td>\n","      <td>5-hydroxytryptamine</td>\n","      <td>5ht</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>impedance cardiogram</td>\n","      <td>icg</td>\n","      <td>impedance cardiogram</td>\n","      <td>icg</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>first derivative of icg</td>\n","      <td>dz/dt</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1497</th>\n","      <td>sialyl lewis x</td>\n","      <td>sle(x)</td>\n","      <td>sialyl lewis x</td>\n","      <td>sle(x)</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1242</td>\n","    </tr>\n","    <tr>\n","      <th>1498</th>\n","      <td>transcriptional regulatory network</td>\n","      <td>trn</td>\n","      <td>transcriptional regulatory network</td>\n","      <td>trn</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1245</td>\n","    </tr>\n","    <tr>\n","      <th>1499</th>\n","      <td>methoxychlor</td>\n","      <td>mxc</td>\n","      <td>methoxychlor</td>\n","      <td>mxc</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1246</td>\n","    </tr>\n","    <tr>\n","      <th>1500</th>\n","      <td>gonadotropin-releasing hormone</td>\n","      <td>gnrh</td>\n","      <td>gonadotropin-releasing hormone</td>\n","      <td>gnrh</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1246</td>\n","    </tr>\n","    <tr>\n","      <th>1501</th>\n","      <td>fanconi anemia</td>\n","      <td>fa</td>\n","      <td>fanconi anemia</td>\n","      <td>fa</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1249</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1502 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5eb80a58-125b-44fe-8251-f0cb753b2bf2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5eb80a58-125b-44fe-8251-f0cb753b2bf2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5eb80a58-125b-44fe-8251-f0cb753b2bf2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["#@title Xem số trường hợp dự đoán sai\n","# Calculate TP, FP, FN\n","TP = sum(final_contigency_table['TP'])\n","FP = sum(final_contigency_table['FP'])\n","FN = sum(final_contigency_table['FN'])\n","M = sum(final_contigency_table['M'])\n","print(f'True positive: {TP}\\n False positve: {FP}\\n False negative: {FN}\\n Modified: {M}')"],"metadata":{"id":"KijXehneHafD","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960585283,"user_tz":-420,"elapsed":81,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"a5543e17-493e-4aa1-fad5-7dfad73a00ad"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["True positive: 921\n"," False positve: 68\n"," False negative: 131\n"," Modified: 138\n"]}]},{"cell_type":"code","source":["#@title Xem các chỉ số đánh giá model\n","# Calculate precision, recall, f1\n","precision = TP/(TP+FP)\n","recall = TP/(TP+FN)\n","f1 = 1/((1/precision+1/recall)/2)\n","print(f'Precision: {precision}\\n Recall: {recall}\\n F1 score: {f1}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNNdrLApEoFB","executionInfo":{"status":"ok","timestamp":1650960585283,"user_tz":-420,"elapsed":74,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"9d5040af-fb95-45d6-e1cc-abd17a2d094a","cellView":"form"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.9312436804853387\n"," Recall: 0.8754752851711026\n"," F1 score: 0.90249877511024\n","\n"]}]},{"cell_type":"code","source":["#@title kiểm tra trường hợp cụ thể\n","idx = 1001 #@param {type: \"number\"}\n","corpus = \"ab3p\" #@param [\"ab3p\", \"bioadi\"]\n","sentence = ab3p.documents[idx].passages[1].text\n","BuildContigencyTable(sentence,corpus,idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"nwQAXGPI8-Tj","executionInfo":{"status":"ok","timestamp":1650960585284,"user_tz":-420,"elapsed":68,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"35d2417d-7a5b-400d-c1e7-256124914dd9","cellView":"form"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                longform shortform               truelongform  \\\n","0                        radial arteries        ra            radial arteries   \n","1                              diltiazem      dilt                  diltiazem   \n","2                30 microm of mibefradil      mibe                        NaN   \n","3                             mibefradil      mibe                 mibefradil   \n","4  verapamil+ 30 microm of nitroglycerin    vp-ntg                        NaN   \n","5             30 microm of nitroglycerin    vp-ntg                        NaN   \n","6                          nitroglycerin    vp-ntg                        NaN   \n","7                                    NaN       NaN  verapamil + nitroglycerin   \n","\n","  trueshortform  TP  FP  FN  M   idx  \n","0            ra   1   0   0  0  1001  \n","1          dilt   1   0   0  0  1001  \n","2           NaN   0   0   0  0  1001  \n","3          mibe   1   0   0  0  1001  \n","4           NaN   0   0   0  0  1001  \n","5           NaN   0   0   0  0  1001  \n","6           NaN   0   0   0  0  1001  \n","7        vp-ntg   0   0   0  1  1001  "],"text/html":["\n","  <div id=\"df-a274653b-c43a-43f2-9ffa-c40ee10628aa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longform</th>\n","      <th>shortform</th>\n","      <th>truelongform</th>\n","      <th>trueshortform</th>\n","      <th>TP</th>\n","      <th>FP</th>\n","      <th>FN</th>\n","      <th>M</th>\n","      <th>idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>radial arteries</td>\n","      <td>ra</td>\n","      <td>radial arteries</td>\n","      <td>ra</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>diltiazem</td>\n","      <td>dilt</td>\n","      <td>diltiazem</td>\n","      <td>dilt</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>30 microm of mibefradil</td>\n","      <td>mibe</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>mibefradil</td>\n","      <td>mibe</td>\n","      <td>mibefradil</td>\n","      <td>mibe</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>verapamil+ 30 microm of nitroglycerin</td>\n","      <td>vp-ntg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>30 microm of nitroglycerin</td>\n","      <td>vp-ntg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>nitroglycerin</td>\n","      <td>vp-ntg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1001</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>verapamil + nitroglycerin</td>\n","      <td>vp-ntg</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1001</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a274653b-c43a-43f2-9ffa-c40ee10628aa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a274653b-c43a-43f2-9ffa-c40ee10628aa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a274653b-c43a-43f2-9ffa-c40ee10628aa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["# Kiểm tra model với văn bản mới"],"metadata":{"id":"usSmT37jsdtw"}},{"cell_type":"code","source":["print(\"Nhập đoạn văn\")\n","text = input()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-khLwU7pslNT","executionInfo":{"status":"ok","timestamp":1650960590029,"user_tz":-420,"elapsed":4763,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"297c48cb-eaa6-48ed-ad92-c5d087632e88"},"execution_count":31,"outputs":[{"name":"stdout","output_type":"stream","text":["Nhập đoạn văn\n","Here we provide the frst computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.\n"]}]},{"cell_type":"markdown","source":["Dự đoán token cho tác vụ sentence classification"],"metadata":{"id":"xeBIm0d6g66U"}},{"cell_type":"code","source":["PredictTokenSentence(text)"],"metadata":{"id":"JWkhyAo2tY0b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650960600387,"user_tz":-420,"elapsed":437,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"55128727-719d-4008-9642-03fe6f32fb4a"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['S',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'B',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'I',\n"," 'S',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O',\n"," 'O']"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["Dự đoán các câu chứa cặp từ viết tắt/định nghĩa"],"metadata":{"id":"1dkyYFsXgYdV"}},{"cell_type":"code","source":["PredictSentenceWithABBR(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7zigPLNspW7","executionInfo":{"status":"ok","timestamp":1650960603532,"user_tz":-420,"elapsed":452,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"0287e61a-fc23-444a-875f-db6e498059a8"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods.']"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["Dự doán token cho tác vụ gán nhãn LFSF trong câu"],"metadata":{"id":"wqkNucvegcs9"}},{"cell_type":"code","source":["sentenceIdx = 0 # chỉ số câu dự đoán\n","sentence = PredictSentenceWithABBR(text)[sentenceIdx]\n","PredictToken(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFteTusUt0UZ","executionInfo":{"status":"ok","timestamp":1650960606024,"user_tz":-420,"elapsed":626,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"89c4be6e-a5b0-4ccd-b382-66bb3b8c6fd5"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('[CLS]', 'TAG'),\n"," ('we', 'O'),\n"," ('validated', 'O'),\n"," ('an', 'O'),\n"," ('entirely', 'O'),\n"," ('redes', 'O'),\n"," ('##igned', 'O'),\n"," ('version', 'O'),\n"," ('of', 'O'),\n"," ('our', 'O'),\n"," ('neural', 'O'),\n"," ('network', 'O'),\n"," ('-', 'O'),\n"," ('based', 'O'),\n"," ('model', 'O'),\n"," (',', 'O'),\n"," ('alpha', 'O'),\n"," ('##fold', 'O'),\n"," (',', 'O'),\n"," ('in', 'O'),\n"," ('the', 'O'),\n"," ('challenging', 'O'),\n"," ('14', 'B-LF'),\n"," ('##th', 'I-LF'),\n"," ('critical', 'B-LF'),\n"," ('assessment', 'I-LF'),\n"," ('of', 'I-LF'),\n"," ('protein', 'B-LF'),\n"," ('structure', 'I-LF'),\n"," ('prediction', 'L-LF'),\n"," ('(', 'U-PR'),\n"," ('cas', 'U-SF'),\n"," ('##p', 'U-SF'),\n"," ('##14', 'U-SF'),\n"," (')', 'U-PR'),\n"," ('15', 'O'),\n"," (',', 'O'),\n"," ('demonstrating', 'O'),\n"," ('accuracy', 'O'),\n"," ('competitive', 'O'),\n"," ('with', 'O'),\n"," ('experimental', 'O'),\n"," ('structures', 'O'),\n"," ('in', 'O'),\n"," ('a', 'O'),\n"," ('majority', 'O'),\n"," ('of', 'O'),\n"," ('cases', 'O'),\n"," ('and', 'O'),\n"," ('greatly', 'O'),\n"," ('outperform', 'O'),\n"," ('##ing', 'O'),\n"," ('other', 'O'),\n"," ('methods', 'O'),\n"," ('.', 'O'),\n"," ('[SEP]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'U-PR'),\n"," ('[PAD]', 'U-SF'),\n"," ('[PAD]', 'U-SF'),\n"," ('[PAD]', 'U-SF'),\n"," ('[PAD]', 'U-SF'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'O'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'U-SF'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG'),\n"," ('[PAD]', 'TAG')]"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["Dự đoán cặp LFSF từ câu"],"metadata":{"id":"Nyja2KqnhmL_"}},{"cell_type":"code","source":["predictLFSFFromSentence(sentence)"],"metadata":{"id":"Jp4QDCxGhmMA","colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"status":"ok","timestamp":1650960617985,"user_tz":-420,"elapsed":634,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"e6b28493-8907-4f8c-fa12-53c6591aacd6"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            longform shortform\n","0  14th critical assessment of protein structure ...    casp14\n","1  critical assessment of protein structure predi...    casp14\n","2                       protein structure prediction    casp14"],"text/html":["\n","  <div id=\"df-cf2bddf4-014f-4bc6-8bb4-0cf05ba086e4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longform</th>\n","      <th>shortform</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14th critical assessment of protein structure ...</td>\n","      <td>casp14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>critical assessment of protein structure predi...</td>\n","      <td>casp14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>protein structure prediction</td>\n","      <td>casp14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf2bddf4-014f-4bc6-8bb4-0cf05ba086e4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cf2bddf4-014f-4bc6-8bb4-0cf05ba086e4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cf2bddf4-014f-4bc6-8bb4-0cf05ba086e4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["Dự đoán cặp LFSF từ đoạn văn"],"metadata":{"id":"iO60KsJPhC2f"}},{"cell_type":"code","source":["predictLFSFFromPassage(text)"],"metadata":{"id":"UdhaTOretAOZ","colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"status":"ok","timestamp":1650960619846,"user_tz":-420,"elapsed":17,"user":{"displayName":"Hoàng Hiệp Đặng","userId":"09498793559338135353"}},"outputId":"dd663587-77c3-4495-eb9e-40d9eb95d6e8"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            longform shortform\n","0  14th critical assessment of protein structure ...    casp14\n","1  critical assessment of protein structure predi...    casp14\n","2                       protein structure prediction    casp14"],"text/html":["\n","  <div id=\"df-f8848b01-38f1-4748-8017-99f8fff3d0cd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longform</th>\n","      <th>shortform</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14th critical assessment of protein structure ...</td>\n","      <td>casp14</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>critical assessment of protein structure predi...</td>\n","      <td>casp14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>protein structure prediction</td>\n","      <td>casp14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8848b01-38f1-4748-8017-99f8fff3d0cd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f8848b01-38f1-4748-8017-99f8fff3d0cd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f8848b01-38f1-4748-8017-99f8fff3d0cd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}]}]}